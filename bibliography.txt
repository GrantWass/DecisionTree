Some background: I have never used c++ but have had one class in C. I understand the pointers and memory management
side of things but the syntax I will need a lot of help on.

Starting: I didn't really start until the study session. I looked at the documentation and attended your session 
and leaving that I was able to get a pretty strong idea of where to go from helper

I wrote a lot of psuedocode or python style code for the functions based on the logic that was needed. I did this because
I wanted to get the logic written, not caring too much about syntax. After that I slowly moved towards the right syntax, 
often using ChatGPT to fill in the knowledge gaps. An example is below


Code I gave to GPT:

int lowerImpurity = 0;
int upperImpurity = 0;
int yesCountLower = 0;
int noCountLower = 0;
int yesCountUpper = 0;
int noCountUpper = 0;
for (int i = 0; i < attributeData.size(); i++)
{
    if (attributeData[i] < threshold) // lower impurity
    {
        if (outcomes[i] == 1)
        {
            yesCountLower++;
        }
        else
        {
            noCountLower++;
        }
    }
    else // upper impurity
    {
        if (outcomes[i] == 1)
        {
            yesCountUpper++;
        }
        else
        {
            noCountUpper++;
        }
    }
}
int overallCount = attributeData.size();
int upperCount = yesCountUpper + noCountUpper;
int lowerCount = yesCountLower + noCountLower;
lowerImpurity = 1 - (yesCountLower / lowerCount) * *2 - (noCountLower / lowerCount)**2;
upperImpurity = 1 - (yesCountUpper / upperCount) * *2 - (noCountUpper / upperCount)**2;
// calculate weighted impurity (based on partition sizes)
int weightedImpurity = (lowerCount / overallCount) * lowerImpurity + (upperCount / overallCount) * upperImpurity;

CHATGPT RESPONSE

double lowerImpurity = 0.0;
double upperImpurity = 0.0;
int yesCountLower = 0, noCountLower = 0;
int yesCountUpper = 0, noCountUpper = 0;

int overallCount = attributeData.size();
if (overallCount == 0) return 0; // Avoid division by zero

for (size_t i = 0; i < attributeData.size(); i++) {
    if (attributeData[i] < threshold) { // lower impurity
        if (outcomes[i] == 1) {
            yesCountLower++;
        } else {
            noCountLower++;
        }
    } else { // upper impurity
        if (outcomes[i] == 1) {
            yesCountUpper++;
        } else {
            noCountUpper++;
        }
    }
}

int lowerCount = yesCountLower + noCountLower;
int upperCount = yesCountUpper + noCountUpper;

if (lowerCount > 0) {
    double pYesLower = static_cast<double>(yesCountLower) / lowerCount;
    double pNoLower = static_cast<double>(noCountLower) / lowerCount;
    lowerImpurity = 1.0 - (pYesLower * pYesLower) - (pNoLower * pNoLower);
}

if (upperCount > 0) {
    double pYesUpper = static_cast<double>(yesCountUpper) / upperCount;
    double pNoUpper = static_cast<double>(noCountUpper) / upperCount;
    upperImpurity = 1.0 - (pYesUpper * pYesUpper) - (pNoUpper * pNoUpper);
}

// Calculate weighted impurity (based on partition sizes)
double weightedImpurity = (static_cast<double>(lowerCount) / overallCount) * lowerImpurity +
                          (static_cast<double>(upperCount) / overallCount) * upperImpurity;

I did this for many of my functions to get the syntax correct. ChatGPT also noticed the occasional error in my code 
which was certainly helpful. (like above it realized I used an int when I should've used a double)

Used GPT to help me understand how to handle the base case of trainSubtree. I knew it would be
when we had no more data to split on but was unsure how to implement

When testing on my code I came across some compiliation errors. ChatGPT was 
able to help me decipher errors in the tests to figure that out.

Finishing: I think I was able to get around 90% of the logic and code written but I still had a
couple of failing test cases. One of them revolved around not considering a node with a right child
but not a left child in my classification. The other was an error about passing by reference instead
of value which caused my data and outcomes to be out of sync. Although ChatGPT wasn't able to tell me
where my code was incorect is seriously helped me create a framework of logging outputs to identify 
where these problems occured.

Overall I really enjoyed this project as it was a fun way to applied knowledge we have learned to
an actual implementation. I saw this project as fun challange and it was able to make me think in 
a way that was guided and not frustrating, which was good.
